{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0c273f0a-58d9-43d7-a489-905769e4d590",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from itertools import combinations\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "03587d79-270c-4e27-bfc0-f1cae5efca60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project Paths\n",
    "# Define the root project directory and construct paths to relevant subdirectories\n",
    "project_root = os.path.abspath(os.path.join(os.path.dirname(os.getcwd())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cf4cf47a-f07d-4fef-86f4-f90dd5ed19f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "basics_dir_path = os.path.join(project_root, 'data', 'section_1_basics')\n",
    "team_box_scores_dir_path = os.path.join(project_root, 'data', 'section_2_team_box_scores')\n",
    "geography_dir_path = os.path.join(project_root, 'data', 'section_3_geography')\n",
    "public_rankings_dir_path = os.path.join(project_root, 'data', 'section_4_public_rankings')\n",
    "supplements_dir_path = os.path.join(project_root, 'data', 'section_5_supplements')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "10602878-15f9-480b-bc89-5f4e097e76f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling Pipeline\n",
    "# Load regular season results for a given gender ('M' or 'W')\n",
    "def load_regular_season_results(gender, season):\n",
    "    filename = f\"{gender}RegularSeasonCompactResults.csv\"\n",
    "    reg_res = pd.read_csv(os.path.join(basics_dir_path, filename))\n",
    "    return reg_res[reg_res['Season'] < season]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2d065761-d08f-4b37-9362-85582ab026d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tournament seed data and extract numerical seed value\n",
    "def load_seed_data(gender, season):\n",
    "    filename = f\"{gender}NCAATourneySeeds.csv\"\n",
    "    seeds_df = pd.read_csv(os.path.join(basics_dir_path, filename))\n",
    "    seeds_df = seeds_df[seeds_df['Season'] < season]\n",
    "    return seeds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b5467a7c-d198-4ee2-a0e5-ae2cdcf7fbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Tournament Data\n",
    "def load_tourney_data(gender, season):\n",
    "    filename = f\"{gender}NCAATourneyCompactResults.csv\"\n",
    "    tourney_df = pd.read_csv(os.path.join(basics_dir_path, filename))\n",
    "    return tourney_df[tourney_df['Season'] < season]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9329c227-0496-403e-b54b-5eb8423036b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Regular Season Data\n",
    "def create_matchups(tourney_df):\n",
    "    rows = []\n",
    "    for _, row in tourney_df.iterrows():\n",
    "        team1 = min(row['WTeamID'], row['LTeamID'])\n",
    "        team2 = max(row['WTeamID'], row['LTeamID'])\n",
    "        team1won = 1 if team1 == row['WTeamID'] else 0\n",
    "        rows.append({\n",
    "            'season': row['Season'],\n",
    "            'team1ID': team1,\n",
    "            'team2ID': team2,\n",
    "            'team1won': team1won\n",
    "        })\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4054a43b-f90b-464d-b8fb-1dda0436dc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate team's regular season stats into one df\n",
    "def aggregate_team_stats(df):\n",
    "    w_stats = df.groupby(['Season', 'WTeamID']).agg(\n",
    "        w_score_avg=('WScore', 'mean'),\n",
    "        w_games=('WScore', 'count')\n",
    "    ).rename_axis(['Season', 'TeamID']).reset_index()\n",
    "    \n",
    "    l_stats = df.groupby(['Season', 'LTeamID']).agg(\n",
    "        l_score_avg=('LScore', 'mean'),\n",
    "        l_games=('LScore', 'count')\n",
    "    ).rename_axis(['Season', 'TeamID']).reset_index()\n",
    "\n",
    "    stats = pd.merge(w_stats, l_stats, on=['Season', 'TeamID'], how='outer').fillna(0)\n",
    "    stats['games'] = stats['w_games'] + stats['l_games']\n",
    "    stats['win_rate'] = stats['w_games'] / stats['games']\n",
    "    stats['avg_score'] = (stats['w_score_avg'] * stats['w_games'] + stats['l_score_avg'] * stats['l_games']) / stats['games']\n",
    "    return stats[['Season', 'TeamID', 'avg_score', 'games', 'win_rate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "15de7d89-7eb8-4621-8793-c402db70821b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate all valid matchups for a given season\n",
    "def generate_matchups(team_df, season):\n",
    "    team_ids = team_df['TeamID'].unique()\n",
    "    pairs = [(a, b) for a, b in combinations(team_ids, 2)]\n",
    "    return pd.DataFrame({\n",
    "        'Season': season,\n",
    "        'team1ID': [min(a, b) for a, b in pairs],\n",
    "        'team2ID': [max(a, b) for a, b in pairs]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d5bf5167-fb67-4015-89bb-85a7a37a5d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up Training Data Matrix\n",
    "def prep_training_data(gender):\n",
    "    regular_season_df = load_regular_season_results('M', 2025)\n",
    "    seeds_df = load_seed_data('M', 2025)\n",
    "    tourney_df = load_tourney_data('M', 2025)\n",
    "    \n",
    "    #Create ALL Valid Tournament Matchups Per Season\n",
    "    matchups_df = create_matchups(tourney_df)\n",
    "    team_stats = aggregate_team_stats(regular_season_df)\n",
    "\n",
    "    seeds_df['Seed'] = seeds_df['Seed'].str.extract('(\\d+)').astype(int)\n",
    "    matchups_df = matchups_df.rename(columns={'season': 'Season'})\n",
    "    team_stats = team_stats.rename(columns={'season': 'Season'})\n",
    "    seeds_df = seeds_df.rename(columns={'Season': 'Season'})\n",
    "\n",
    "    # Rename for merging\n",
    "    team1_seeds = seeds_df.rename(columns={'Season':'Season', 'TeamID': 'team1ID', 'Seed': 'team1_seed'})\n",
    "    team2_seeds = seeds_df.rename(columns={'Seaspn':'Season','TeamID': 'team2ID', 'Seed': 'team2_seed'})\n",
    "\n",
    "    # Merge all df's into one\n",
    "    merged_df = matchups_df \\\n",
    "        .merge(team1_seeds[['Season', 'team1ID', 'team1_seed']], on=['Season', 'team1ID'], how='left') \\\n",
    "        .merge(team2_seeds[['Season', 'team2ID', 'team2_seed']], on=['Season', 'team2ID'], how='left') \\\n",
    "        .merge(team_stats.rename(columns={'TeamID': 'team1ID', 'avg_score': 'team1_avg_score', 'games': 'team1_games', 'win_rate': 'team1_win_rate'}), on=['Season', 'team1ID'], how='left') \\\n",
    "        .merge(team_stats.rename(columns={'TeamID': 'team2ID', 'avg_score': 'team2_avg_score', 'games': 'team2_games', 'win_rate': 'team2_win_rate'}), on=['Season', 'team2ID'], how='left')\n",
    "\n",
    "    # Feature Engineering Seed Differences and Score Differences\n",
    "    merged_df['seed_diff'] = merged_df['team1_seed'] - merged_df['team2_seed']\n",
    "    merged_df['score_diff'] = merged_df['team1_avg_score'] - merged_df['team2_avg_score']\n",
    "\n",
    "    cols = [\n",
    "        'team1_seed', 'team1_avg_score', 'team1_games', 'team1_win_rate',\n",
    "        'team2_seed', 'team2_avg_score', 'team2_games', 'team2_win_rate',\n",
    "        'seed_diff', 'score_diff',\n",
    "        'team1won'\n",
    "    ]\n",
    "    merged_df = merged_df[cols]\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "409a1632-af55-43bd-b71d-32b85b43ce52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y):\n",
    "    X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    #Split Training into train and valid\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.25, random_state=42\n",
    "    )\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_valid_scaled = scaler.transform(X_valid)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    return scaler, X_train_scaled, y_train, X_valid_scaled, y_valid, X_test_scaled, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a96b03f8-36a5-4abe-a96f-3fd4fda428d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_train_model(X_train_scaled, y_train, X_valid_scaled, y_valid):\n",
    "    model = TabNetClassifier()\n",
    "    model.fit(X_train=X_train_scaled, y_train=y_train, eval_set=[(X_valid_scaled, y_valid)])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a1b43291-b73e-4bdd-8ee5-76f7890b31d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_stats(model, X_test_scaled, y_test, gender):\n",
    "    pred = model.predict(X_test_scaled)\n",
    "    probs = model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "    print(f\"{gender} Model Accuracy:\", accuracy_score(y_test, pred))\n",
    "    brier = brier_score_loss(y_test, probs)\n",
    "    print(f\"{gender} Model Brier Score: {brier:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "829c6bf7-20b0-4a2e-b314-e66a52054955",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same as prepping training data except without 2025 tourney data because that is what were predicting\n",
    "def create_predicting_features(gender, matchups):\n",
    "    regular_season_df = load_regular_season_results(gender, 2026)\n",
    "    regular_season_df = regular_season_df[regular_season_df['Season'] == 2025]\n",
    "    \n",
    "    seeds_df = load_seed_data(gender, 2026)\n",
    "    seeds_df = seeds_df[seeds_df['Season'] == 2025]\n",
    "\n",
    "    team_stats = aggregate_team_stats(regular_season_df)\n",
    "\n",
    "    seeds_df['Seed'] = seeds_df['Seed'].str.extract('(\\d+)').astype(int)\n",
    "    \n",
    "    matchups = matchups.rename(columns={'season': 'Season'})\n",
    "    team_stats = team_stats.rename(columns={'season': 'Season'})\n",
    "    seeds_df = seeds_df.rename(columns={'Season': 'Season'})\n",
    "\n",
    "    team1_seeds = seeds_df.rename(columns={'Season':'Season', 'TeamID': 'team1ID', 'Seed': 'team1_seed'})\n",
    "    team2_seeds = seeds_df.rename(columns={'Season':'Season','TeamID': 'team2ID', 'Seed': 'team2_seed'})\n",
    "\n",
    "    merged_df = matchups \\\n",
    "        .merge(team1_seeds[['Season', 'team1ID', 'team1_seed']], on=['Season', 'team1ID'], how='left') \\\n",
    "        .merge(team2_seeds[['Season', 'team2ID', 'team2_seed']], on=['Season', 'team2ID'], how='left') \\\n",
    "        .merge(team_stats.rename(columns={'TeamID': 'team1ID', 'avg_score': 'team1_avg_score', 'games': 'team1_games', 'win_rate': 'team1_win_rate'}), on=['Season', 'team1ID'], how='left') \\\n",
    "        .merge(team_stats.rename(columns={'TeamID': 'team2ID', 'avg_score': 'team2_avg_score', 'games': 'team2_games', 'win_rate': 'team2_win_rate'}), on=['Season', 'team2ID'], how='left').fillna(17)\n",
    "\n",
    "    merged_df['seed_diff'] = merged_df['team1_seed'] - merged_df['team2_seed']\n",
    "    merged_df['score_diff'] = merged_df['team1_avg_score'] - merged_df['team2_avg_score']\n",
    "\n",
    "    cols = [\n",
    "        'team1_seed', 'team1_avg_score', 'team1_games', 'team1_win_rate',\n",
    "        'team2_seed', 'team2_avg_score', 'team2_games', 'team2_win_rate',\n",
    "        'seed_diff', 'score_diff'\n",
    "    ]\n",
    "    merged_df = merged_df[cols]\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "962cf193-9fe1-4f1f-9b5f-714d7cb2a574",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kingc\\anaconda3\\envs\\myenv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.78113 | val_0_auc: 0.62406 |  0:00:00s\n",
      "epoch 1  | loss: 0.66906 | val_0_auc: 0.71222 |  0:00:00s\n",
      "epoch 2  | loss: 0.62379 | val_0_auc: 0.74955 |  0:00:00s\n",
      "epoch 3  | loss: 0.58548 | val_0_auc: 0.74707 |  0:00:00s\n",
      "epoch 4  | loss: 0.59038 | val_0_auc: 0.75001 |  0:00:00s\n",
      "epoch 5  | loss: 0.57772 | val_0_auc: 0.75571 |  0:00:00s\n",
      "epoch 6  | loss: 0.57748 | val_0_auc: 0.76476 |  0:00:00s\n",
      "epoch 7  | loss: 0.56846 | val_0_auc: 0.77875 |  0:00:00s\n",
      "epoch 8  | loss: 0.56951 | val_0_auc: 0.78133 |  0:00:00s\n",
      "epoch 9  | loss: 0.56612 | val_0_auc: 0.78224 |  0:00:00s\n",
      "epoch 10 | loss: 0.56302 | val_0_auc: 0.77794 |  0:00:00s\n",
      "epoch 11 | loss: 0.55702 | val_0_auc: 0.77993 |  0:00:00s\n",
      "epoch 12 | loss: 0.56734 | val_0_auc: 0.78309 |  0:00:00s\n",
      "epoch 13 | loss: 0.54017 | val_0_auc: 0.78328 |  0:00:00s\n",
      "epoch 14 | loss: 0.5442  | val_0_auc: 0.78468 |  0:00:00s\n",
      "epoch 15 | loss: 0.56055 | val_0_auc: 0.78895 |  0:00:00s\n",
      "epoch 16 | loss: 0.54599 | val_0_auc: 0.79029 |  0:00:00s\n",
      "epoch 17 | loss: 0.54969 | val_0_auc: 0.79255 |  0:00:01s\n",
      "epoch 18 | loss: 0.54523 | val_0_auc: 0.7924  |  0:00:01s\n",
      "epoch 19 | loss: 0.55523 | val_0_auc: 0.79296 |  0:00:01s\n",
      "epoch 20 | loss: 0.52472 | val_0_auc: 0.79185 |  0:00:01s\n",
      "epoch 21 | loss: 0.55141 | val_0_auc: 0.79058 |  0:00:01s\n",
      "epoch 22 | loss: 0.53024 | val_0_auc: 0.7885  |  0:00:01s\n",
      "epoch 23 | loss: 0.52356 | val_0_auc: 0.78864 |  0:00:01s\n",
      "epoch 24 | loss: 0.52675 | val_0_auc: 0.78724 |  0:00:01s\n",
      "epoch 25 | loss: 0.53916 | val_0_auc: 0.78462 |  0:00:01s\n",
      "epoch 26 | loss: 0.53085 | val_0_auc: 0.78283 |  0:00:01s\n",
      "epoch 27 | loss: 0.51223 | val_0_auc: 0.78185 |  0:00:01s\n",
      "epoch 28 | loss: 0.55397 | val_0_auc: 0.77897 |  0:00:01s\n",
      "epoch 29 | loss: 0.52326 | val_0_auc: 0.77605 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 19 and best_val_0_auc = 0.79296\n",
      "M Model Accuracy: 0.6805555555555556\n",
      "M Model Brier Score: 0.2112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kingc\\anaconda3\\envs\\myenv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\kingc\\anaconda3\\envs\\myenv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.78113 | val_0_auc: 0.62406 |  0:00:00s\n",
      "epoch 1  | loss: 0.66906 | val_0_auc: 0.71222 |  0:00:00s\n",
      "epoch 2  | loss: 0.62379 | val_0_auc: 0.74955 |  0:00:00s\n",
      "epoch 3  | loss: 0.58548 | val_0_auc: 0.74707 |  0:00:00s\n",
      "epoch 4  | loss: 0.59038 | val_0_auc: 0.75001 |  0:00:00s\n",
      "epoch 5  | loss: 0.57772 | val_0_auc: 0.75571 |  0:00:00s\n",
      "epoch 6  | loss: 0.57748 | val_0_auc: 0.76476 |  0:00:00s\n",
      "epoch 7  | loss: 0.56846 | val_0_auc: 0.77875 |  0:00:00s\n",
      "epoch 8  | loss: 0.56951 | val_0_auc: 0.78133 |  0:00:00s\n",
      "epoch 9  | loss: 0.56612 | val_0_auc: 0.78224 |  0:00:00s\n",
      "epoch 10 | loss: 0.56302 | val_0_auc: 0.77794 |  0:00:00s\n",
      "epoch 11 | loss: 0.55702 | val_0_auc: 0.77993 |  0:00:00s\n",
      "epoch 12 | loss: 0.56734 | val_0_auc: 0.78309 |  0:00:00s\n",
      "epoch 13 | loss: 0.54017 | val_0_auc: 0.78328 |  0:00:00s\n",
      "epoch 14 | loss: 0.5442  | val_0_auc: 0.78468 |  0:00:00s\n",
      "epoch 15 | loss: 0.56055 | val_0_auc: 0.78895 |  0:00:00s\n",
      "epoch 16 | loss: 0.54599 | val_0_auc: 0.79029 |  0:00:00s\n",
      "epoch 17 | loss: 0.54969 | val_0_auc: 0.79255 |  0:00:01s\n",
      "epoch 18 | loss: 0.54523 | val_0_auc: 0.7924  |  0:00:01s\n",
      "epoch 19 | loss: 0.55523 | val_0_auc: 0.79296 |  0:00:01s\n",
      "epoch 20 | loss: 0.52472 | val_0_auc: 0.79185 |  0:00:01s\n",
      "epoch 21 | loss: 0.55141 | val_0_auc: 0.79058 |  0:00:01s\n",
      "epoch 22 | loss: 0.53024 | val_0_auc: 0.7885  |  0:00:01s\n",
      "epoch 23 | loss: 0.52356 | val_0_auc: 0.78864 |  0:00:01s\n",
      "epoch 24 | loss: 0.52675 | val_0_auc: 0.78724 |  0:00:01s\n",
      "epoch 25 | loss: 0.53916 | val_0_auc: 0.78462 |  0:00:01s\n",
      "epoch 26 | loss: 0.53085 | val_0_auc: 0.78283 |  0:00:01s\n",
      "epoch 27 | loss: 0.51223 | val_0_auc: 0.78185 |  0:00:01s\n",
      "epoch 28 | loss: 0.55397 | val_0_auc: 0.77897 |  0:00:01s\n",
      "epoch 29 | loss: 0.52326 | val_0_auc: 0.77605 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 19 and best_val_0_auc = 0.79296\n",
      "W Model Accuracy: 0.6805555555555556\n",
      "W Model Brier Score: 0.2112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kingc\\anaconda3\\envs\\myenv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved as submission.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025_1101_1102</td>\n",
       "      <td>0.447608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025_1101_1103</td>\n",
       "      <td>0.828813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025_1101_1104</td>\n",
       "      <td>0.004510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025_1101_1105</td>\n",
       "      <td>0.376583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025_1101_1106</td>\n",
       "      <td>0.322020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71248</th>\n",
       "      <td>2025_3477_3479</td>\n",
       "      <td>0.243521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71249</th>\n",
       "      <td>2025_3477_3480</td>\n",
       "      <td>0.361354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71250</th>\n",
       "      <td>2025_3478_3479</td>\n",
       "      <td>0.355252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71251</th>\n",
       "      <td>2025_3478_3480</td>\n",
       "      <td>0.355252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71252</th>\n",
       "      <td>2025_3479_3480</td>\n",
       "      <td>0.412685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>137319 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ID      Pred\n",
       "0      2025_1101_1102  0.447608\n",
       "1      2025_1101_1103  0.828813\n",
       "2      2025_1101_1104  0.004510\n",
       "3      2025_1101_1105  0.376583\n",
       "4      2025_1101_1106  0.322020\n",
       "...               ...       ...\n",
       "71248  2025_3477_3479  0.243521\n",
       "71249  2025_3477_3480  0.361354\n",
       "71250  2025_3478_3479  0.355252\n",
       "71251  2025_3478_3480  0.355252\n",
       "71252  2025_3479_3480  0.412685\n",
       "\n",
       "[137319 rows x 2 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate_model():\n",
    "    m_df = prep_training_data('M')\n",
    "    cols = [\n",
    "        'team1_seed', 'team1_avg_score', 'team1_games', 'team1_win_rate',\n",
    "        'team2_seed', 'team2_avg_score', 'team2_games', 'team2_win_rate',\n",
    "        'seed_diff', 'score_diff'\n",
    "    ]\n",
    "    m_X = m_df[cols]\n",
    "    m_y = m_df['team1won']\n",
    "    m_scaler, m_X_train_scaled, m_y_train, m_X_valid_scaled, m_y_valid, m_X_test_scaled, m_y_test = split_data(m_X, m_y)\n",
    "    m_model = create_and_train_model(m_X_train_scaled, m_y_train, m_X_valid_scaled, m_y_valid)\n",
    "    model_stats(m_model, m_X_test_scaled, m_y_test, 'M')\n",
    "    m_teams = pd.read_csv(os.path.join(basics_dir_path, \"MTeams.csv\"))\n",
    "    m_teams = m_teams[m_teams['LastD1Season']==2025]\n",
    "    m_matchups = generate_matchups(m_teams, 2025)\n",
    "    m_pred_df = create_predicting_features('M', m_matchups)\n",
    "    m_pred_scaled = m_scaler.transform(m_pred_df)\n",
    "    m_probs = m_model.predict_proba(m_pred_scaled)[:,1]\n",
    "    m_matchups['ID'] = m_matchups.apply(lambda row: f\"2025_{int(row.team1ID)}_{int(row.team2ID)}\", axis=1)\n",
    "    m_matchups['Pred'] = m_probs\n",
    "    men_submission = m_matchups[['ID', 'Pred']]\n",
    "\n",
    "    w_df = prep_training_data('W')\n",
    "    w_X = w_df[cols]\n",
    "    w_y = w_df['team1won']\n",
    "    w_scaler, w_X_train_scaled, w_y_train, w_X_valid_scaled, w_y_valid, w_X_test_scaled, w_y_test = split_data(w_X, w_y)\n",
    "    w_model = create_and_train_model(w_X_train_scaled, w_y_train, w_X_valid_scaled, w_y_valid)\n",
    "    model_stats(w_model, w_X_test_scaled, w_y_test, 'W')\n",
    "    w_teams = pd.read_csv(os.path.join(basics_dir_path, \"WTeams.csv\"))\n",
    "    w_matchups = generate_matchups(w_teams, 2025)\n",
    "    w_pred_df = create_predicting_features('W', w_matchups)\n",
    "    w_pred_scaled = w_scaler.transform(w_pred_df)\n",
    "    w_probs = w_model.predict_proba(w_pred_scaled)[:,1]\n",
    "    w_matchups['ID'] = w_matchups.apply(lambda row: f\"2025_{int(row.team1ID)}_{int(row.team2ID)}\", axis=1)\n",
    "    w_matchups['Pred'] = w_probs\n",
    "    women_submission = w_matchups[['ID', 'Pred']]\n",
    "\n",
    "    # Save combined predictions to submission file\n",
    "    submission = pd.concat([men_submission, women_submission])\n",
    "    submission.to_csv(f\"submission.csv\", index=False)\n",
    "    print(f\"Submission file saved as submission.csv\")\n",
    "    return submission\n",
    "evaluate_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef23fb8-89d3-4e1b-9504-9490c5fc2a34",
   "metadata": {},
   "source": [
    "Brier Score for Kaggle Submission: 0.14814"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93a7784-e72e-4018-9f9f-6fdd89ecd586",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
